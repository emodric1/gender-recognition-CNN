# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wO1ZDauJc0dYn5YJJkjU6BYRY8_OJSF7
"""

import sys
import os

"""Za početak je potrebno u Jupyter okruženje instalirati biblioteke koje će koristiti prilikom izrade projekta. Stoga ćemo instalirati opencv-utils, opencv-python, mtcnn i tensorflow. U narednim isječcima koda date su instalacije tih biblioteka."""

!{sys.executable} -m pip install opencv-utils

!{sys.executable} -m pip install opencv-python

!{sys.executable} -m pip install mtcnn

!{sys.executable} -m pip install tensorflow

"""Projekat se okvirno može podijeliti u tri dijela. U prvom dijelu projekta potrebno je pripremiti dataset, drugi dio projekta predtavljao bi treniranje a treći verifikaciju. Stoga se pozabavimo prvim dijelom projekta, odnosno predprocesiranjem dataset-a i pripremanjem istog za korištenje u treniranju i validaciji. U Jupyter notebook-ovim fajlovima kreiran je folder pod nazivom sveslike u kojem su uploadovane fotografije iz dataset-a. 
Ove slike je potrebno učitati u kod. Uz pomoć narednog koda ćemo učitati imena slika u listu fajlovi.
"""

from os import listdir
from os.path import isfile, join
import zipfile

zf = zipfile.ZipFile("utkcropped.zip")
zf.extractall('/content/sveslike')

fajlovi = [f for f in listdir('/content/sveslike') if isfile(join('/content/sveslike', f))]

"""Kada u listi imamo imena slika svog dataset-a, ove slike ćemo funkcijom imread() učitati u listu sa nazivom slike."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
#import matplotlib.image as mpimg
#from matplotlib import ticker
from mtcnn import MTCNN
import cv2

slike=list()
for i in range(0,len(fajlovi)):
  img = cv2.cvtColor(cv2.imread('/content/sveslike/'+fajlovi[i]), cv2.COLOR_BGR2RGB)
  slike.append(img)

"""Učitali smo fotografije i sada se treba preći na pretprocesiranje. Iz biblioteke MTCNN koristit ćemo funkciju detect_faces(). Ukoliko se ne detektuje niti jedno lice na slici potrebno je da tu sliku uklonimo."""

detector = MTCNN()
lista=list()
for i in range(0,len(slike)):
  if len(detector.detect_faces(slike[i]))==0:
    lista.append(i)
lista.sort(reverse=True)
for i in lista:
  fajlovi.pop(i)

"""Konačno, pretprocesirani dataset možemo podijeliti u dva dijela, jedan za trening a drugi za verifikaciju. Dataset možemo podijeliti u omjeru 80%:20% za trening:verifikaciju. Pošto su fotografije sortirane redom po godinama osobe na slici, kako bi u oba seta bila ravnomjerno raspoređena količina osoba po godinama, svaki peti element ćemo ubaciti u set za verifikaciju, a sve ostale u set za treniranje."""

brver=int(len(fajlovi)/5)+1
brtren=len(fajlovi)-brver
verifikacija=np.ndarray((brver,3,64,64),dtype=np.uint8)
trening=np.ndarray((brtren,3,64,64),dtype=np.uint8)
yver=np.ndarray(brver,dtype=np.uint8)
ytren=np.ndarray(brtren,dtype=np.uint8)
for i in range(0,len(fajlovi)):
  #img = cv2.cvtColor(cv2.imread('/content/sveslike/'+fajlovi[i]), cv2.COLOR_BGR2RGB)
  img = cv2.imread('/content/sveslike/'+fajlovi[i], cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE
  img=cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)
  #img=img/255
  a=fajlovi[i].find('_')+1
  b=fajlovi[i].find('_',a,len(fajlovi[i]))
  if i%5==0:
    verifikacija[int(i/5)]=img.T
    yver[int(i/5)]=fajlovi[i][a:b]
  else:
    trening[i-int(i/5)-1]=img.T
    ytren[i-int(i/5)-1]=fajlovi[i][a:b]

trenbrver=int(brtren/5)+1
trenbrtren=brtren-trenbrver
treningver=np.ndarray((trenbrver,3,64,64),dtype=np.uint8)
treningtren=np.ndarray((trenbrtren,3,64,64),dtype=np.uint8)
trenyver=np.ndarray(trenbrver,dtype=np.uint8)
trenytren=np.ndarray(trenbrtren,dtype=np.uint8)
for i in range(0,brtren):
  if i%5==0:
    treningver[int(i/5)]=trening[i]
    trenyver[int(i/5)]=ytren[i]
  else:
    treningtren[i-int(i/5)-1]=trening[i]
    trenytren[i-int(i/5)-1]=ytren[i]
trenver=(treningver, trenyver)



from keras.models import Sequential
from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation
from keras.optimizers import RMSprop, Adam
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping
from keras.utils import np_utils

lr=1e-4
brepoha=30
optimizer = Adam(lr=lr, decay=lr/brepoha)
objective = 'binary_crossentropy'

model = Sequential()

model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(3, 64, 64), activation='relu'))
model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering="th"))

model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))
model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering="th"))

model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))
model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering="th"))

model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))
model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))
#     model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering="th"))



model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])

model.summary()

#brepoha = 30
batch_size = 16
#labs = train_data.iloc[:,1].values.tolist()

## Callback for loss logging per epoch
class LossHistory(Callback):
    def on_train_begin(self, logs={}):
        self.losses = []
        self.val_losses = []
        
    def on_epoch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))

early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')  
history = LossHistory()

model.fit(treningtren, trenytren, batch_size=batch_size, epochs=brepoha, validation_data=trenver, verbose=0, shuffle=True, callbacks=[history, early_stopping])

predikcije = model.predict(verifikacija, verbose=0)
predikcije

loss = history.losses
val_loss = history.val_losses

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('VGG-16 Loss Trend')
plt.plot(loss, 'blue', label='Training Loss')
plt.plot(val_loss, 'green', label='Validation Loss')
plt.xticks(range(0,brepoha)[0::2])
plt.legend()
plt.show()

ypredikcije=np.ndarray(len(predikcije),dtype=np.uint8)
for i in range(0,len(verifikacija)):
    if predikcije[i, 0] >= 0.5: 
        print('I am {:.2%} sure this is a Female'.format(predikcije[i][0]))

    else: 
        print('I am {:.2%} sure this is a Male'.format(1-predikcije[i][0]))
        
    plt.imshow(verifikacija[i].T)
    plt.show()

import collections
type(predikcije)


print((yver==0).sum())
print((yver==1).sum())
print((trenytren==0).sum())
print((trenytren==1).sum())
print((predikcije<0.5).sum())
print((predikcije>=0.5).sum())

pred=np.ndarray(len(predikcije),dtype=np.uint8)
for i in range(0, len(predikcije)):
  if (predikcije[i]<=0.5):
    pred[i]=0
  else:
    pred[i]=1

import sklearn
print(sklearn.metrics.confusion_matrix(yver, pred))
acc=(1629+2041)/(1629+822+197+2041)
acc1=(2203+1450)/(2203+248+788+1450)
acc2=(2174+1889)/(2147+277+349+1889)
print(acc*100)
print(acc1*100)
print(acc2*100)

2898+1791-1943-1808



plt.imshow(verifikacija[7].T)
plt.show()
print(verifikacija[5].shape)

ytren=np.ndarray(5,dtype=np.uint8)
ytren.shape
ytren[0]='1'
ytren[1]='8'
ytren[2]='8'
ytren[3]='1'
ytren[4]='1'
print(ytren)

verifikacija.shape
trening.shape
len(fajlovi)

import collections
print(collections.Counter(yver))
print(collections.Counter(ytren))
print((83/126)*100)
print((359/473)*100)

for j in (range(0,len(fajlovi))):
  if j%5==0:
    j
  else:
    print(j-int(j/5))

#BOUNDING BOX
from mtcnn import MTCNN
import cv2

img = cv2.cvtColor(cv2.imread('/content/34_1_1_20170114024710355.jpg.chip.jpg'), cv2.COLOR_BGR2RGB)
detector = MTCNN()
bounding_box=detector.detect_faces(img)[0].get('box')

pt1 = (bounding_box[0], bounding_box[1])
pt2 = (bounding_box[2], bounding_box[3])
cv2.rectangle(img, pt1, pt2, (255, 0, 0),2 )

plt.imshow(img)
plt.show()

from zipfile import ZipFile
with ZipFile('foo.zip', 'r') as zf:
    zf.extractall('destination_path/')

#ILI

from shutil import unpack_archive
unpack_archive('foo.zip', 'destination_path/')

len(slike)

len(fajlovi)

brver

brtren















brver=int(len(fajlovi)/5)+1
brtren=len(fajlovi)-brver
verifikacija=np.ndarray((brver,224,224,3),dtype=np.uint8)
trening=np.ndarray((brtren,224,224,3),dtype=np.uint8)
yver=np.ndarray(brver,dtype=np.uint8)
ytren=np.ndarray(brtren,dtype=np.uint8)
for i in range(0,len(fajlovi)):
  #img = cv2.cvtColor(cv2.imread('/content/sveslike/'+fajlovi[i]), cv2.COLOR_BGR2RGB)
  img = cv2.imread('/content/sveslike/'+fajlovi[i], cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE
  img=cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)
  #img=img/255
  a=fajlovi[i].find('_')+1
  b=fajlovi[i].find('_',a,len(fajlovi[i]))
  if i%5==0:
    verifikacija[int(i/5)]=img
    yver[int(i/5)]=fajlovi[i][a:b]
  else:
    trening[i-int(i/5)-1]=img
    ytren[i-int(i/5)-1]=fajlovi[i][a:b]

verifikacija.shape

trenbrver=int(brtren/5)+1
trenbrtren=brtren-trenbrver
treningver=np.ndarray((trenbrver,224,224,3),dtype=np.uint8)
treningtren=np.ndarray((trenbrtren,224,224,3),dtype=np.uint8)
trenyver=np.ndarray(trenbrver,dtype=np.uint8)
trenytren=np.ndarray(trenbrtren,dtype=np.uint8)
for i in range(0,brtren):
  if i%5==0:
    treningver[int(i/5)]=trening[i]
    trenyver[int(i/5)]=ytren[i]
  else:
    treningtren[i-int(i/5)-1]=trening[i]
    trenytren[i-int(i/5)-1]=ytren[i]
trenver=(treningver, trenyver)

import keras
from keras.preprocessing import image
from keras.callbacks import ModelCheckpoint,EarlyStopping
from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation
from keras.layers import Conv2D, AveragePooling2D
from keras.models import Model, Sequential
from sklearn.model_selection import train_test_split
from keras import metrics
from keras.models import model_from_json
from keras.optimizers import Adam


model = Sequential()
model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))
model.add(Convolution2D(64, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(128, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, (3, 3), activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
 
model.add(Convolution2D(4096, (7, 7), activation='relu'))
model.add(Dropout(0.5))
model.add(Convolution2D(4096, (1, 1), activation='relu'))
model.add(Dropout(0.5))
model.add(Convolution2D(2622, (1, 1)))
model.add(Flatten())
model.add(Activation('softmax'))

lr=1e-4
brepoha = 250
batch_size = 256
optimizer = Adam(lr=lr, decay=lr/brepoha)
objective = 'binary_crossentropy'
model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])

model.summary()

from keras.callbacks import Callback
class LossHistory(Callback):
    def on_train_begin(self, logs={}):
        self.losses = []
        self.val_losses = []
        
    def on_epoch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))

early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')  
history = LossHistory()

model.fit(treningtren, trenytren, batch_size=batch_size, epochs=brepoha, validation_data=trenver, verbose=0, shuffle=True, callbacks=[history, early_stopping])







#freeze all layers of VGG-Face except last 7 one
for layer in model.layers[:-7]:
    layer.trainable = False

base_model_output = Sequential()
base_model_output = Convolution2D(2, (1, 1), name='predictions')(model.layers[-4].output)
base_model_output = Flatten()(base_model_output)
base_model_output = Activation('softmax')(base_model_output)

gender_model = Model(inputs=model.input, outputs=base_model_output)

#check trainable layers
if False:
    for layer in model.layers:
        print(layer, layer.trainable)
    
    print("------------------------")
    for layer in age_model.layers:
        print(layer, layer.trainable)

sgd = keras.optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)

gender_model.compile(loss='categorical_crossentropy'
                  , optimizer=keras.optimizers.Adam()
                  #, optimizer = sgd
                  , metrics=['accuracy']
                 )

checkpointer = ModelCheckpoint(
    filepath='classification_gender_model.hdf5'
    , monitor = "val_loss"
    , verbose=1
    , save_best_only=True
    , mode = 'auto'
)

scores = []

enableFit = True

if enableFit:
    epochs = 250
    batch_size = 256

    for i in range(epochs):
        print("epoch ",i)
        
        ix_train = np.random.choice(train_x.shape[0], size=batch_size)
        
        score = gender_model.fit(
            train_x[ix_train], train_y[ix_train]
            , epochs=1
            , validation_data=(test_x, test_y)
            , callbacks=[checkpointer]
        )
        
        scores.append(score)
        
        from keras.models import load_model
        gender_model = load_model("classification_gender_model.hdf5")
        
        gender_model.save_weights('gender_model_weights.h5')
        
else:
    #pre-trained weights for gender prediction: https://drive.google.com/file/d/1wUXRVlbsni2FN9-jkS_f4UTUrm1bRLyk/view?usp=sharing
    gender_model.load_weights("gender_model_weights.h5")

from keras.preprocessing import image
img = image.load_img('/content/1_0_0_20161219140642920.jpg.chip.jpg', grayscale=False, target_size=(128,128))
x = image.img_to_array(img).reshape(1, -1)[0]

x



